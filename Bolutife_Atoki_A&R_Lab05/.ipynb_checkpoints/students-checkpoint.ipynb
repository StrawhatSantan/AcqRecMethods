{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DISPARITY AND DEPTH MAPS</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center;\">\n",
    "    <img src=\"https://img.freepik.com/premium-vector/warning-signs-high-voltage-hazard-isolated-white-background_68708-427.jpg?w=2000\" alt=\"Image Alt Text\" width=\"50\" height=\"50\" style=\"margin-right: 20px;\">\n",
    "    <div style=\"font-size: 15px;margin-right: 30px\">\n",
    "            Each lab must be completed before the beginning of the other lab session. \n",
    "        <br> \n",
    "          <strong>Don't forget to entitle your .ipynb file with your name and surname. <strong>\n",
    "        <br> \n",
    "         The final submission of the first module has to be done <strong> by Tuesday 27<sup> th</sup>October before 10 am.</strong>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "      <td style=\"border-left: 3px solid rgba(114, 147, 203, 0.9); background-color: rgba(114, 147, 203, 0.1); font-size: 15px; color: blakc; padding-left: 30px;\">\n",
    "        Don't forget to legend your figures and graphs. Interpretations are expected and must by short but comprehensive.  \n",
    "      </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contact : meghna.parameswaran-ayyar@u-bordeaux.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://docs.opencv.org/3.4/stereo_depth.jpg\" width=\"300\" height=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will be two parts to this lab.\n",
    "\n",
    "1. **Disparity Maps**: Generate the map using stereo (Left & Right) images and OpenCV algorithms\n",
    "2. **Depth Maps**: Using a Neural Network\n",
    "\n",
    "\n",
    "The main goals of this lab is to be able to understand how to read library and Git documentation and use pre-existing code for your own images. For the OpenCV functions you are expected to try different parameters to understand how they work and how the choice of stereo images affects the final output.\n",
    "\n",
    "For the Neural Network we provide two options. But you are welcome to try out anything else you may find and compare the results with one of the given networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2> OPENCV : Disparity map </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import opencv, numpy and matplotlib libraries ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to have a left and a right image. You have three choices :\n",
    "- use the provided images \n",
    "- take a picture placing your phone on your left eye, then another (without moving) on your right eye\n",
    "- take a stereo image from the internet (using google images). As they are provided as a single SBS image, you will have to cut it into two images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the images using cv2.imread() . Display both using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can compute a disparity map using StereoBM or StereoSGBM algorithms. You can choose which one you prefer.\n",
    "- for StereoBM refer to : https://docs.opencv.org/3.4/dd/d53/tutorial_py_depthmap.html\n",
    "- for StereoSGBM : https://www.programcreek.com/python/example/110664/cv2.StereoSGBM_create\n",
    "\n",
    "In both case, you will have to play with the parameters to obtain a decent (i.e. smooth) disparity map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Comment on what parameters were the most important to be tuned and the quality of the output (visual quality) that you observe. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other references\n",
    "\n",
    "- General unformal : https://lookingglassfactory.com/blog/depth-map\n",
    "- Block matching : https://en.wikipedia.org/wiki/Block-matching_algorithm\n",
    "- Stereo BM: three-step search algo : https://www.digitalxplore.org/up_proc/pdf/62-1397565973101-104.pdf and https://www.sciencedirect.com/science/article/pii/S1877050915007346\n",
    "- Stereo SGBM: Semi-Global Matching : https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.88.8897&rep=rep1&type=pdf\n",
    "\n",
    "If you are interested then you may check the other algorithm you did choose and see the initial results to comment on how the time and the final output differ from the one you chose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> MONOCULAR DEPTH ESTIMATION USING A DNN (Deep Neural Network)<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of DNN for creating a depth map using only one image. I suggest you try :\n",
    "- MiDaS https://github.com/isl-org/MiDaS\n",
    "- MonoDepth2 : https://github.com/nianticlabs/monodepth2\n",
    "\n",
    "\n",
    "You can also choose another DNN if you want.\n",
    "To use them, simply clone the git repository and use the model (there are different models for different results in MiDaS for example). You don't have to retrain the model. All instructions are in the git.\n",
    "You only need one image as an input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MiDaS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MonoDepth2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on the outputs that you get with the two models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tips at some point, get better images that work well a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "\n",
    "- https://paperswithcode.com/task/monocular-depth-estimation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
